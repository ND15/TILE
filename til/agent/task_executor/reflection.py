import logging
from typing import Dict
import ollama
from base import Task, ExecutionResult


# TODO
#  this part is important since whatever task comes from the user
#  it should get reflected upon before preparing the task list
#  maybe take the user input if they want to proceed in that way
#  else iterate again

class Reflection:
    """
    Reflection Class for LLM Client
        1. Maintains a history of chats along
        2. Returns a successfully generated response
    """

    def __init__(self, llm_client: any):
        self.llm = llm_client
        self.history: Dict[str, str] = {}
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.DEBUG)

    @staticmethod
    def generate_reflection_prompt():
        reflection_prompt = """
        you are a Python programming assistant. You will be given some python code. 
        Your goal is to write a few sentences to explain why your implementation is wrong as indicated by errors. 
        You will need this as a hint when you try again later.
        Please reflect on:
        1. If it is in the right direction related to the task.
        2. What specific errors or issues occurred during execution
        3. What logical problems exist in the code
        4. How the code structure could be improved
        5. What edge cases might cause problems
        6. How to make the code more robust

        Provide a detailed reflection that will help generate a better solution.
        Do not provide the implementation. 
        DO NOT ASK TO INSTALL PACKAGES.
        DO NOT SETUP ENVIRONMENTS

        You should respond in the following json format:
            {{
                task: str
                reflection: str
            }}
        """

        return reflection_prompt

    def generate_reflection(self, reflection_prompt, code_response, user_prompt):
        messages = [
            ollama.Message(role='system', content=reflection_prompt),
            ollama.Message(role='assistant', content=f'Your code response: {str(code_response)}'),
            ollama.Message(role='user', content=user_prompt)
        ]

        response = ollama.chat(model=self.llm,
                               messages=messages,
                               format='json')

        return response['message']['content']

    def feedback_with_reflection(self, task: Task, result: ExecutionResult):
        if result.error:
            user_prompt = (f"Task: {task.name}"
                           f"Task Description: {task.description}"
                           f"Task Response: {result.output}"
                           f"\nError occured during execution of {task.name}: {task.description}: {result.error}")

            self.logger.info(f"Error encountered and passed to LLM: {result.error}")
        else:
            user_prompt = (f"Task: {task.name}"
                           f"Task: {str(task.description)}"
                           f"Task Response: {str(result.output)}"
                           f"\nNo response was generated for {str(task)}: {str(task.description)}")

            self.logger.info(f"No response was generated by the LLM: {result.error}")

        reflection_prompt = self.generate_reflection_prompt()

        reflection_response = self.generate_reflection(reflection_prompt, result.output, user_prompt)

        feedback_message = f"""For Task: {task.description} 
                               Task Response: {result.output}, 
                               An Error occurred while executing the code, the feedback {reflection_response} is provided to you, 
                               Please modify and update your code for the appropriate response."""

        self.logger.warning(f"Reflection Feedback: {str(reflection_response)}")

        return feedback_message


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )

    task = Task(
        id=1,
        name="find_length_of_string",
        description="Calculate length of a string",
        status='pending'
    )

    result = ExecutionResult(status='failure',
                             output="""from dataclasses import dataclass\nfrom enum import Enum\n@dataclass\nclass Message:\nrole: str\ncontent: []\nprint(Message(role="as", content=assd))""",
                             error="""Traceback (most recent call last): File "/home/nikhil/mine/rag/planner/v3/utils/utils.py", line 7, in <module>\nprint(Message(role="as", content=assd))^^^^NameError: name 'assd' is not defined""")

    Reflection('qwen2.5-coder:7b-instruct-q6_K').feedback_with_reflection(task, result)
